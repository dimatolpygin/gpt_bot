import OpenAI from 'openai';
import { config } from '../config/index.js';
import { File } from 'node:buffer';

const openai = new OpenAI({ apiKey: config.OPENAI_API_KEY });

const SYSTEM = {
  role: 'system',
  content: 'Ð¢Ñ‹ ÑƒÐ¼Ð½Ñ‹Ð¹ Ð¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ AI-Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° ÑÐ·Ñ‹ÐºÐµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ. Ð‘ÑƒÐ´ÑŒ Ñ‡Ñ‘Ñ‚ÐºÐ¸Ð¼, ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼ Ð¸ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼.',
};

const REASONING_MODELS = ['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5.2', 'gpt-5.2-pro', 'gpt-5.2-codex'];

export const THINKING_EMOJI = {
  none:  'ðŸ’­',
  low:   'ðŸ§ ',
  medium:'ðŸ§ ðŸ§ ',
  high:  'ðŸ§ ðŸ§ ðŸ§ ',
  xhigh: 'ðŸ§ âš¡',
};

// ÐžÐ±Ñ‘Ñ€Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº OpenAI
const wrapError = (err) => {
  if (err.status === 429) throw new Error('ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² OpenAI. ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ.');
  if (err.status === 401) throw new Error('ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ OpenAI API ÐºÐ»ÑŽÑ‡.');
  if (err.status === 404) throw new Error(`ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° Ð² Ð²Ð°ÑˆÐµÐ¼ Ð°ÐºÐºÐ°ÑƒÐ½Ñ‚Ðµ OpenAI.`);
  if (err.status === 400) throw new Error(`ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: ${err.message}`);
  throw err;
};

const normalizeHistory = (history) => history.map(m => ({ role: m.role, content: m.content }));

// â”€â”€ Streaming Ñ‡ÐµÑ€ÐµÐ· Responses API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export const streamChat = async (messages, modelId, onChunk, onDone, options = {}) => {
  try {
    const { thinkingLevel = 'none', webSearch = false } = options;
    const model = modelId || config.OPENAI_MODEL;
    const params = {
      model,
      input: [
        { role: 'system', content: SYSTEM.content },
        ...normalizeHistory(messages),
      ],
      stream: true,
    };

    if (REASONING_MODELS.includes(model) && thinkingLevel !== 'none') {
      params.reasoning = { effort: thinkingLevel };
    }

    if (webSearch) {
      params.tools = [{ type: 'web_search_preview' }];
    }

    const stream = await openai.responses.create(params);
    let fullText = '';
    for await (const chunk of stream) {
      const delta = chunk.delta?.text || '';
      if (delta) {
        fullText += delta;
        if (onChunk) await onChunk(fullText);
      }
    }
    if (onDone) await onDone(fullText);
    return fullText;
  } catch (err) {
    wrapError(err);
  }
};

// â”€â”€ Web Search Ñ‡ÐµÑ€ÐµÐ· Responses API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export const webSearchChat = async (history, modelId) => {
  try {
    const model = modelId || config.OPENAI_MODEL;
    const response = await openai.responses.create({
      model,
      tools: [{ type: 'web_search_preview' }],
      input: [
        { role: 'system', content: SYSTEM.content },
        ...normalizeHistory(history),
      ],
    });
    return response.output_text ?? '';
  } catch (err) {
    wrapError(err);
  }
};

// â”€â”€ ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ð¾Ñ‚Ð¾ (vision) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export const analyzePhoto = async (imageUrl, caption, modelId) => {
  try {
    const model = modelId || 'gpt-4o';
    const response = await openai.chat.completions.create({
      model,
      messages: [{
        role: 'user',
        content: [
          { type: 'image_url', image_url: { url: imageUrl } },
          { type: 'text', text: caption || 'ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ Ð¾Ð¿Ð¸ÑˆÐ¸ Ñ‡Ñ‚Ð¾ Ð½Ð° ÑÑ‚Ð¾Ð¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸.' },
        ],
      }],
    });
    return response.choices[0]?.message?.content ?? '';
  } catch (err) {
    wrapError(err);
  }
};

const getMimeType = (fileName) => {
  const ext = fileName?.split('.').pop()?.toLowerCase();
  const types = {
    pdf: 'application/pdf',
    txt: 'text/plain',
    md: 'text/markdown',
    csv: 'text/csv',
    json: 'application/json',
    js: 'text/javascript',
    ts: 'text/typescript',
    py: 'text/x-python',
    docx: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
  };
  return types[ext] || 'application/octet-stream';
};

export const analyzeFile = async (fileBuffer, fileName, caption, modelId) => {
  let uploaded;
  try {
    const file = new File([fileBuffer], fileName, { type: getMimeType(fileName) });
    uploaded = await openai.files.create({ file, purpose: 'user_data' });

    const response = await openai.responses.create({
      model: modelId || 'gpt-4o',
      input: [
        {
          role: 'user',
          content: [
            { type: 'input_file', file_id: uploaded.id },
            { type: 'input_text', text: caption || 'ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÑ‚Ð¾Ñ‚ Ñ„Ð°Ð¹Ð» Ð¸ Ð¾Ð¿Ð¸ÑˆÐ¸ ÐµÐ³Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ.' },
          ],
        },
      ],
    });

    return response.output_text ?? '';
  } catch (err) {
    wrapError(err);
  } finally {
    if (uploaded?.id) {
      await openai.files.del(uploaded.id).catch(() => {});
    }
  }
};
