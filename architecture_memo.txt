╔══════════════════════════════════════════════════════════════════════════════╗
║              ПАМЯТКА ПО АРХИТЕКТУРЕ — GPT Telegram Bot                     ║
║              Составлена: февраль 2026                                       ║
╚══════════════════════════════════════════════════════════════════════════════╝


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  1. ОБЩАЯ СХЕМА ПОТОКА ДАННЫХ
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Пользователь
      │
      │  (сообщение / фото / команда)
      ▼
  Telegram Server
      │
      │  long polling (Telegraf)
      ▼
  src/index.js  ──── запускает Express (WebApp) + бот
      │
      ├── bot/middleware/auth.js     ← БЛОКИРУЕТ если не в ALLOWED_USERS
      │
      ├── bot/handlers/start.js      ← /start, /menu, /new, /dialogs, /help
      ├── bot/handlers/dialogs.js    ← управление диалогами
      ├── bot/handlers/chat.js       ← текст + фото → GPT
      └── bot/handlers/callbacks.js  ← нажатия inline-кнопок

  Параллельно:
      src/server.js  ─── Express на порту 3000
          └── GET  /webapp       → отдаёт index.html
          └── POST /api/history  → возвращает историю из Supabase


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  2. ЧТО ЗА ЧТО ОТВЕЧАЕТ (СЕРВИСЫ)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  ┌─────────────────────────────────────────────────────────────────────────┐
  │  services/supabase.js  →  ДОЛГОСРОЧНОЕ ХРАНИЛИЩЕ (PostgreSQL)          │
  │                                                                         │
  │  Таблицы:                                                               │
  │    bot_users          — пользователи (telegram_id, username, created)   │
  │    bot_conversations  — диалоги (id, user_id, title, created_at)        │
  │    bot_messages       — сообщения (id, conv_id, role, content, model)   │
  │                                                                         │
  │  Функции:                                                               │
  │    getOrCreateUser(telegramId)  — авто-регистрация при /start           │
  │    createConversation(userId)   — новый диалог                          │
  │    addMessage(convId, role, content, model) — сохранить сообщение       │
  │    getMessages(convId, limit)   — загрузить историю для GPT контекста   │
  │    getConversations(userId)     — список диалогов пользователя          │
  │    deleteConversation(convId)   — удалить диалог со всеми сообщениями   │
  │    getUserPrompts(userId)       — список сохранённых системных промтов │
  │    addUserPrompt(…)             — сохранить новый промт (name + content)│
  │    setActivePrompt(userId, promptId) — переключить активный промт       │
  │    deleteUserPrompt(userId, promptId) — удалить ненужный промт          │
  │    getActivePrompt(userId) → { name, content } — подставляется в GPT    │
  │    getUserPrompts(userId)       — список сохранённых системных промтов │
  │    addUserPrompt(…)             — сохранить новый промт (name + content)│
  │    setActivePrompt(userId, promptId) — переключить активный промт       │
  │    deleteUserPrompt(userId, promptId) — удалить ненужный промт          │
  │    getActivePrompt(userId) → { name, content } — подставляется в GPT    │
  └─────────────────────────────────────────────────────────────────────────┘

  ┌─────────────────────────────────────────────────────────────────────────┐
  │  services/redis.js  →  БЫСТРЫЙ ВРЕМЕННЫЙ КЭШHРАНИЛИЩЕ                  │
  │  (подробнее в секции 3)                                                 │
  └─────────────────────────────────────────────────────────────────────────┘

  ┌─────────────────────────────────────────────────────────────────────────┐
  │  services/openai.js  →  ВЗАИМОДЕЙСТВИЕ С GPT                           │
  │                                                                         │
  │  Функции:                                                               │
  │    streamChat(messages, model, onChunk)                                 │
  │      — стримит ответ GPT, вызывает onChunk на каждый кусок текста       │
  │      — используется в chat.js для обновления сообщения в реалтайме      │
  │                                                                         │
  │    webSearchChat(messages, model, onChunk)                              │
  │      — то же самое, но через Responses API с веб-поиском                │
  │                                                                         │
  │    analyzePhoto(imageBase64, caption, model)                            │
  │      — vision-запрос: отправляет фото + текст → получает описание       │
  │                                                                         │
  │    generateImage(prompt, size)                                          │
  │      — новый endpoint: вызывает gpt-image-1.5 (или gpt-image-1)         │
  │        ✔ оптимизирует промт через gpt-4o-mini                          │
  │        ✔ автоматически выбирает размер и отправляет фото                │
  │                                                                         │
  │    transcribeVoice(audioBuffer)                                        │
  │      — Whisper → преобразует голос в текст и переиспользует chat.js     │
  │                                                                         │
  │    mdToHtml(text)                                                       │
  │      — вспомогательная функция: Markdown → HTML перед отправкой reply   │
   └─────────────────────────────────────────────────────────────────────────┘


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  3. REDIS — ДЛЯ ЧЕГО ИСПОЛЬЗУЕТСЯ (4 КЛЮЧА)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Redis НЕ заменяет базу данных. Он используется для 4 конкретных задач:

  ┌───────────────────────────────────────────────────────────────────────┐
  │  [1] PROCESSING LOCK  —  ключ: lock:{userId}  —  TTL: 90 сек         │
  │                                                                       │
  │  Проблема: пользователь отправил сообщение и сразу шлёт ещё одно.    │
  │  GPT ещё не ответил → возникнут два параллельных запроса к OpenAI    │
  │  → два ответа в неправильном порядке → каша в диалоге.               │
  │                                                                       │
  │  Решение: при получении сообщения ставим lock в Redis.               │
  │  Если lock уже есть → бот отвечает "⏳ Подождите, обрабатывается...". │
  │  После ответа GPT → lock снимается.                                  │
  │  Если GPT завис > 90 сек → lock автоматически исчезает (TTL).        │
  └───────────────────────────────────────────────────────────────────────┘

  ┌───────────────────────────────────────────────────────────────────────┐
  │  [2] АКТИВНЫЙ ДИАЛОГ  —  ключ: conv:{userId}  —  TTL: без лимита     │
  │                                                                       │
  │  Хранит ID текущего открытого диалога пользователя.                  │
  │  Зачем: когда пользователь пишет текст, боту нужно знать             │
  │  В КАКОЙ диалог добавить сообщение, без запроса к БД.                │
  │                                                                       │
  │  Устанавливается при: /new, openDialog(), /start                     │
  └───────────────────────────────────────────────────────────────────────┘

  ┌───────────────────────────────────────────────────────────────────────┐
  │  [3] ВЫБРАННАЯ МОДЕЛЬ  —  ключ: model:{userId}  —  TTL: 30 дней      │
  │                                                                       │
  │  Пользователь выбрал gpt-4o → сохраняется в Redis.                  │
  │  При следующем сообщении бот читает модель из Redis (быстро),        │
  │  не делая запрос в Supabase каждый раз.                              │
  │                                                                       │
  │  Доступные модели: gpt-4o, gpt-4o-mini, gpt-5, gpt-5-mini,          │
  │                    gpt-5-nano, gpt-5.2, gpt-5.2-pro, gpt-5.2-codex  │
  └───────────────────────────────────────────────────────────────────────┘

  ┌───────────────────────────────────────────────────────────────────────┐
  │  [4] WEB SEARCH TOGGLE  —  ключ: wsearch:{userId}  —  TTL: 30 дней   │
  │                                                                       │
  │  Флаг вкл/выкл веб-поиска для конкретного пользователя.             │
  │  Виден в меню как "🌐 Web Search: вкл/выкл".                         │
  │  Если вкл → вызывается webSearchChat() вместо streamChat().          │
  └───────────────────────────────────────────────────────────────────────┘

  ┌───────────────────────────────────────────────────────────────────────┐
  │  [5] ФЛАГ ПЕРЕИМЕНОВАНИЯ  —  ключ: rename:{userId}  —  TTL: ~5 мин   │
  │                                                                       │
  │  Когда пользователь нажимает "✏️ Переименовать" → ставится Redis флаг.│
  │  Следующее текстовое сообщение перехватывается не как чат с GPT,     │
  │  а как новое название диалога.                                       │
  │  После сохранения нового имени → флаг снимается.                     │
  └───────────────────────────────────────────────────────────────────────┘

  ┌───────────────────────────────────────────────────────────────────────┐
  │  [6] РЕЖИМ ДОБАВЛЕНИЯ ПРОМТА  —  ключ: prompt_add_state:{userId}     │
  │                            — TTL: 5 минут                            │
  │                                                                       │
  │  Нажатие кнопки «➕ Добавить промт» устанавливает этот ключ.         │
  │  Следующее текстовое сообщение не отправляется в GPT, а парсится как  │
  │  "Название | Текст промта" и сохраняется в Supabase.                │
  │  После сохранения пользователь получает уведомление и кнопки промтов.│
  └───────────────────────────────────────────────────────────────────────┘


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  4. ПАРАЛЛЕЛЬНАЯ ОБРАБОТКА — ЕСТЬ ЛИ ОЧЕРЕДИ?
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  ОЧЕРЕДЕЙ НЕТ. Архитектура проще:

  ┌───────────────────────────────────────────────────────────────────────┐
  │  Параллельность — НА УРОВНЕ ПОЛЬЗОВАТЕЛЕЙ                             │
  │                                                                       │
  │  User A → сообщение → обрабатывается асинхронно (async/await)        │
  │  User B → сообщение → обрабатывается ПАРАЛЛЕЛЬНО с User A            │
  │  User C → то же самое                                                 │
  │                                                                       │
  │  Node.js event loop + async/await обеспечивают это автоматически.    │
  │  Пока GPT стримит ответ для User A, бот принимает сообщения User B.  │
  └───────────────────────────────────────────────────────────────────────┘

  ┌───────────────────────────────────────────────────────────────────────┐
  │  Параллельность — НА УРОВНЕ ОДНОГО ПОЛЬЗОВАТЕЛЯ                       │
  │                                                                       │
  │  Намеренно ЗАБЛОКИРОВАНА через Processing Lock (Redis).              │
  │  Один пользователь = максимум 1 активный GPT-запрос одновременно.    │
  │  Это защита от дублей и сохранение порядка сообщений.                │
  └───────────────────────────────────────────────────────────────────────┘

  ┌───────────────────────────────────────────────────────────────────────┐
  │  GPT СТРИМИНГ — как работает                                          │
  │                                                                       │
  │  1. Отправляем запрос к OpenAI                                        │
  │  2. OpenAI возвращает текст по кускам (chunks)                        │
  │  3. На каждый chunk вызывается onChunk(delta)                         │
  │  4. Накапливаем полный текст в буфер                                  │
  │  5. Каждые 800мс (throttle) → редактируем сообщение в Telegram        │
  │     (editMessageText) — пользователь видит "печатающийся" ответ       │
  │  6. По окончании стрима → финальное редактирование                   │
  │  7. Сохраняем полный ответ в Supabase                                 │
  │  8. Снимаем Processing Lock                                           │
  │                                                                       │
  │  Почему throttle 800мс? Telegram API лимит: 30 editMessage/сек,       │
  │  при стриминге без throttle упрёмся в rate limit.                    │
  └───────────────────────────────────────────────────────────────────────┘


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  5. ЖИЗНЕННЫЙ ЦИКЛ ОДНОГО СООБЩЕНИЯ
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Пользователь пишет "Привет":

  [1]  auth.js         → проверить userId в ALLOWED_USERS → пропустить/заблок
  [2]  chat.js         → получили текстовое сообщение
  [3]  Redis           → проверить rename:{userId} → нет флага, продолжаем
  [4]  Redis           → проверить lock:{userId}   → нет лока, ставим lock
  [5]  Redis           → читаем conv:{userId}      → получаем convId
  [6]  Redis           → читаем model:{userId}     → получаем "gpt-4o"
  [7]  Redis           → читаем wsearch:{userId}   → web search выкл
  [8]  Supabase        → addMessage(convId, "user", "Привет")
  [9]  Supabase        → getMessages(convId, 20)   → история для контекста
  [10] Telegram        → bot.sendMessage("⏳")      → временное сообщение
  [11] OpenAI          → streamChat(messages, "gpt-4o", onChunk)
  [12] каждые 800мс   → editMessageText(накопленный текст)
  [13] стрим закончен → editMessageText(финальный текст + кнопки)
  [14] Supabase        → addMessage(convId, "assistant", полный_ответ, "gpt-4o")
  [15] Redis           → del lock:{userId}  ← РАЗБЛОКИРУЕМ


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  6. СТРУКТУРА ФАЙЛОВ
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  src/
  ├── index.js                  Точка входа. Запускает Express, затем bot.launch()
  ├── config/index.js           Читает .env: BOT_TOKEN, OPENAI_KEY, SUPABASE_*, PORT...
  ├── server.js                 Express: GET /webapp, POST /api/history + HMAC проверка
  │
  ├── services/
  │   ├── openai.js             GPT: streamChat / webSearchChat / analyzePhoto
  │   ├── supabase.js           CRUD для всех таблиц БД
  │   └── redis.js              Работа с ioredis: get/set/del ключей
  │
  ├── bot/
  │   ├── middleware/
  │   │   └── auth.js           Whitelist фильтр по ALLOWED_USERS
  │   ├── handlers/
  │   │   ├── start.js          /start, /menu, /new, /dialogs, /help
  │   │   ├── dialogs.js        showDialogs (пагинация), openDialog, createNewDialog
  │   │   ├── chat.js           Обработка текста и фото → вызов OpenAI
  │   │   └── callbacks.js      Все нажатия inline-кнопок
  │   └── keyboards/
  │       ├── main.js           Главное меню (InlineKeyboard)
  │       ├── dialogs.js        Список / внутри диалога / подтверждение удаления
  │       └── models.js         Выбор модели + capability map (vision/webSearch/tokens)
  │
  └── webapp/
      └── index.html            Telegram WebApp: история диалога с MD рендерингом


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  7. CAPABILITY MAP МОДЕЛЕЙ
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  keyboards/models.js хранит таблицу совместимости:

  Модель            Chat   Vision   WebSearch   Примечание
  ─────────────────────────────────────────────────────────
  gpt-4o             ✅      ✅        ✅
  gpt-4o-mini        ✅      ✅        ✅        Быстрый/дешёвый
  gpt-5              ✅      ✅        ✅        Флагман
  gpt-5-mini         ✅      ✅        ✅
  gpt-5-nano         ✅      ❌        ❌        Самый лёгкий
  gpt-5.2            ✅      ✅        ✅
  gpt-5.2-pro        ✅      ✅        ✅
  gpt-5.2-codex      ✅      ❌        ❌        Код-специализация

  Перед каждым запросом → проверяется совместимость.
  Если пользователь отправил фото, а модель не поддерживает vision →
  понятное сообщение об ошибке вместо краша.


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  8. ИНФРАСТРУКТУРА
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Локальная разработка:
    Windows 11 / VS Code / PowerShell
    nodemon src/index.js              — автоперезапуск при изменениях
    Cloudflare Tunnel → localhost:3000 — временный HTTPS URL для WebApp
    Upstash Redis (облако)            — не нужно поднимать Redis локально
    Telegram API через HTTP прокси    — proxy.market (обход блокировок)

  Продакшн (планируется):
    Docker Compose                    — контейнер с ботом
    VPS Beget или аналог              — хостинг
    GitHub Actions (SSH deploy)       — push в main → автодеплой на VPS
    Постоянный домен                  — вместо Cloudflare Tunnel

  Git ветки:
    main   — стабильный продакшн
    dev    — разработка, сюда пушим изменения, затем merge в main


━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  9. КРАТКАЯ ШПАРГАЛКА — "ЧТО ГДЕ ЛЕЖИТ"
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Хочу...                              Иду в...
  ────────────────────────────────────────────────────────────────────────
  Изменить ответ GPT / промпт          services/openai.js
  Добавить новую команду бота          bot/handlers/start.js
  Добавить новую кнопку в меню         bot/keyboards/main.js + callbacks.js
  Изменить логику диалогов             bot/handlers/dialogs.js
  Изменить что хранится в БД           services/supabase.js
  Добавить новый Redis-ключ            services/redis.js
  Изменить WebApp интерфейс            src/webapp/index.html
  Добавить новый API эндпоинт          src/server.js
  Изменить список разрешённых юзеров   .env → ALLOWED_USERS
  Добавить/убрать модель GPT           bot/keyboards/models.js
  Изменить порт WebApp                 .env → PORT
